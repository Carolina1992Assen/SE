import pickle
from pieter import tf_idf 
from nltk.tokenize import TweetTokenizer, RegexpTokenizer
from itertools import permutations
import re

def del_symbols(text):
    result = re.sub(r"[()+-.../#]", r"", text)
    return result


def del_emojis(text):
    return text.encode('ascii', 'ignore').decode('ascii')


def del_tw(text):
    result = re.sub(r"https\S+", "", text)
    return result


def del_rt(text):
    result = re.sub(r"RT", "", text)
    return result


def del_punct(s):
    result = s.translate(str.maketrans("", "", string.punctuation))
    return result
    
del td(w1, w2):
    docs = pickle.load(open('docs.pickle', 'rb'))
    words_index = pickle.load(open('words_index.pickle', 'rb'))
    for item in docs.values():
        words = item[2]
        words = del_emojis(words)
        words = del_tw(words)
        words = del_rt(words)
        words_ = del_symbols(words)
        words = tw_tok.tokenize(words)
        
        w1_count = w1_count + words.count(w1)
        w2_count = w2_count + words.count(w2)
        words_found = w1_count + w2_count
        
        if words_found == 1:
            swf = 1
        else:
            swf = 2
        
        tf = swf / words_found
        df = swf / len(words)
        idf = np.log(len(docs.keys()) / (df + 1))
        tf_idf = tf * idf
        if math.isnan(tf_idf):
            tf_idf = 0         
        else:
            tf_idf = round(tf_idf, 3)
                
                
        if dictorhighestscore == 'highestscore':
            score = tf_idf
            if tf_idf > score:
                score = tf_idf
                return score
